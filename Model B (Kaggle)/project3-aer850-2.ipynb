{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13869986,"sourceType":"datasetVersion","datasetId":8837157},{"sourceId":13870911,"sourceType":"datasetVersion","datasetId":8837749},{"sourceId":13883937,"sourceType":"datasetVersion","datasetId":8845809}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Starting Step 2\n\nPhone Verify Account to Turn on Internet (Session options)\n\nOnce GPU enabled, use T4 or P100.\n\nfirst thing before you run the code, \"pip install ultralytics\" in the console at the bottom\n\nmake sure you turn on draft session (with accelerator) before you start training and don't turn it off until you have all the data.","metadata":{}},{"cell_type":"code","source":"###############################################################\n# EXTRACT ULTRALYTICS WHEEL & IMPORT LOCALLY (KAGGLE SAFE\n###############################################################\n\nimport os\nimport zipfile\nimport glob\nimport sys\nimport shutil\n\nprint(\"Searching for ultralytics wheel...\")\n\n# Locate the uploaded wheel file\nwheel_files = glob.glob(\"/kaggle/input/**/*.whl\", recursive=True)\n\nif not wheel_files:\n    raise FileNotFoundError(\"No .whl file found. Please upload an ultralytics-8.3.x wheel file.\")\n\nWHEEL_PATH = wheel_files[0]\nprint(\"Wheel located at:\", WHEEL_PATH)\n\n# Define extraction directory\nEXTRACT_DIR = \"/kaggle/working/ultralytics_lib\"\n\n# Remove previous extraction directory if it exists\nif os.path.exists(EXTRACT_DIR):\n    print(\"Removing previous extraction directory...\")\n    shutil.rmtree(EXTRACT_DIR)\n\n# Extract the wheel contents\nprint(\"Extracting wheel contents...\")\nwith zipfile.ZipFile(WHEEL_PATH, \"r\") as z:\n    z.extractall(EXTRACT_DIR)\n\n# Add extracted directory to Python path\nsys.path.insert(0, EXTRACT_DIR)\n\nprint(\"Importing Ultralytics from extracted wheel...\")\nfrom ultralytics import YOLO\n\nprint(\"Ultralytics successfully imported without pip installation.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:05:06.089437Z","iopub.execute_input":"2025-12-01T19:05:06.089796Z","iopub.status.idle":"2025-12-01T19:05:06.337634Z","shell.execute_reply.started":"2025-12-01T19:05:06.089772Z","shell.execute_reply":"2025-12-01T19:05:06.337087Z"}},"outputs":[{"name":"stdout","text":"Searching for ultralytics wheel...\nWheel located at: /kaggle/input/ultralytics-8-3-232/ultralytics-8.3.232-py3-none-any.whl\nRemoving previous extraction directory...\nExtracting wheel contents...\nImporting Ultralytics from extracted wheel...\nUltralytics successfully imported without pip installation.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"###############################################\n# AER850 ‚Äì PROJECT 3 ‚Äì KAGGLE FULL PIPELINE\n# YOLOv11 + PCB Masking + Training + Evaluation\n# OOM-SAFE CONFIG FOR TESLA T4\n###############################################\n\nimport os\nimport glob\nimport shutil\nimport random\nimport zipfile\nimport sys\nimport cv2\nimport torch\nimport numpy as np\n\n# ------------------------------------------------------------\n# 0. Install / import Ultralytics from wheel (offline)\n# ------------------------------------------------------------\n\ndef install_ultralytics_from_wheel():\n    wheel_files = glob.glob(\"/kaggle/input/**/*.whl\", recursive=True)\n    if not wheel_files:\n        raise FileNotFoundError(\"Ultralytics .whl not found in /kaggle/input.\")\n    wheel_path = wheel_files[0]\n\n    extract_dir = \"/kaggle/working/ultralytics_lib\"\n    if not os.path.exists(extract_dir):\n        os.makedirs(extract_dir, exist_ok=True)\n        with zipfile.ZipFile(wheel_path, \"r\") as z:\n            z.extractall(extract_dir)\n\n    if extract_dir not in sys.path:\n        sys.path.insert(0, extract_dir)\n\n    from ultralytics import YOLO\n    return YOLO\n\n\nYOLO = install_ultralytics_from_wheel()\n\n# ------------------------------------------------------------\n# 1. Global paths / settings\n# ------------------------------------------------------------\n\nINPUT_ROOT = \"/kaggle/input\"\nPROJECT_ROOT = \"/kaggle/working\"\nMASK_OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"mask_outputs\")\nFINAL_OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"project3_outputs\")\nRUNS_DETECT_DIR = os.path.join(PROJECT_ROOT, \"runs\", \"detect\")\n\nMODEL_NAME = \"pcb_model_best_kaggle\"\n\nIMG_SIZE = 1280\nBATCH_SIZE = 4\nEPOCHS = 200\nEARLY_STOP_PATIENCE = 20\n\nRUN_MASKING = True\nRUN_TRAINING = True\nRUN_EVALUATION = True\n\nSEED = 42\n\n# ------------------------------------------------------------\n# 2. Seed / device setup\n# ------------------------------------------------------------\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    try:\n        torch.manual_seed(seed)\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed_all(seed)\n    except:\n        pass\n\ndef get_device():\n    if torch.cuda.is_available():\n        return \"cuda\"\n    return \"cpu\"\n\n# ------------------------------------------------------------\n# 3. Finders: data.yaml, motherboard image, weights, eval images\n# ------------------------------------------------------------\n\ndef find_data_yaml():\n    paths = glob.glob(os.path.join(INPUT_ROOT, \"**\", \"data.yaml\"), recursive=True)\n    if not paths:\n        raise FileNotFoundError(\"data.yaml not found in /kaggle/input.\")\n    return paths[0]\n\ndef find_motherboard_image():\n    images = []\n    for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.JPG\",\"*.JPEG\",\"*.PNG\"):\n        images.extend(glob.glob(os.path.join(INPUT_ROOT, \"**\", ext), recursive=True))\n    matches = [f for f in images if \"motherboard\" in os.path.basename(f).lower()]\n    if not matches:\n        raise FileNotFoundError(\"No motherboard image found in /kaggle/input.\")\n    return matches[0]\n\ndef find_yolo_weights():\n    paths = glob.glob(os.path.join(INPUT_ROOT, \"**\", \"yolo*.pt\"), recursive=True)\n    if not paths:\n        raise FileNotFoundError(\"YOLO weights not found in /kaggle/input.\")\n    return paths[0]\n\ndef find_evaluation_images():\n    images = []\n    for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.JPG\",\"*.JPEG\",\"*.PNG\"):\n        for f in glob.glob(os.path.join(INPUT_ROOT, \"**\", ext), recursive=True):\n            if os.path.basename(os.path.dirname(f)).lower() == \"evaluation\":\n                images.append(f)\n    if not images:\n        raise FileNotFoundError(\"No evaluation images found in folder named 'evaluation'.\")\n    return sorted(images)\n\n# ------------------------------------------------------------\n# 4. Step 1 ‚Äî PCB masking\n# ------------------------------------------------------------\n\ndef step1_masking(motherboard_path):\n    os.makedirs(MASK_OUTPUT_DIR, exist_ok=True)\n\n    img = cv2.imread(motherboard_path)\n    if img is None:\n        raise FileNotFoundError(\"Could not read motherboard image.\")\n\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    blur = cv2.GaussianBlur(gray, (7, 7), 0)\n    edges = cv2.Canny(blur, 100, 200)\n    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    if not contours:\n        raise RuntimeError(\"No contours detected.\")\n\n    largest = max(contours, key=cv2.contourArea)\n    mask = np.zeros_like(gray)\n    cv2.drawContours(mask, [largest], -1, 255, -1)\n    pcb = cv2.bitwise_and(img, img, mask=mask)\n\n    cv2.imwrite(os.path.join(MASK_OUTPUT_DIR, \"01_original.jpg\"), img)\n    cv2.imwrite(os.path.join(MASK_OUTPUT_DIR, \"02_gray.jpg\"), gray)\n    cv2.imwrite(os.path.join(MASK_OUTPUT_DIR, \"03_blur.jpg\"), blur)\n    cv2.imwrite(os.path.join(MASK_OUTPUT_DIR, \"04_edges.jpg\"), edges)\n    cv2.imwrite(os.path.join(MASK_OUTPUT_DIR, \"05_mask.jpg\"), mask)\n    cv2.imwrite(os.path.join(MASK_OUTPUT_DIR, \"06_pcb_extracted.jpg\"), pcb)\n\n# ------------------------------------------------------------\n# 5. Step 2 ‚Äî Training YOLO (OOM-safe)\n# ------------------------------------------------------------\n\ndef step2_training(device, yaml_path):\n    weights_path = find_yolo_weights()\n    model = YOLO(weights_path)\n\n    os.makedirs(RUNS_DETECT_DIR, exist_ok=True)\n\n    model.train(\n        data=yaml_path,\n        imgsz=IMG_SIZE,\n        epochs=EPOCHS,\n        batch=BATCH_SIZE,\n        device=device,\n        workers=1,\n        amp=False,\n        mosaic=0.0,\n        fliplr=0.3,\n        flipud=0.2,\n        hsv_h=0.015,\n        patience=EARLY_STOP_PATIENCE,\n        cache=False,\n        plots=True,\n        project=RUNS_DETECT_DIR,\n        name=MODEL_NAME,\n        exist_ok=True,\n    )\n\n    run_folder = os.path.join(RUNS_DETECT_DIR, MODEL_NAME)\n\n    metrics = model.val(\n        data=yaml_path,\n        imgsz=IMG_SIZE,\n        device=device,\n        save=True,\n        plots=True,\n        project=RUNS_DETECT_DIR,\n        name=MODEL_NAME,\n        exist_ok=True,\n    )\n\n    with open(os.path.join(run_folder, \"metrics_summary.txt\"), \"w\") as f:\n        f.write(str(metrics))\n\n    return run_folder\n\n# ------------------------------------------------------------\n# 6. Step 3 ‚Äî Evaluation\n# ------------------------------------------------------------\n\ndef step3_eval(device, run_folder):\n    best_weights = os.path.join(run_folder, \"weights\", \"best.pt\")\n    if not os.path.isfile(best_weights):\n        raise FileNotFoundError(\"best.pt not found; training may not have finished.\")\n\n    model = YOLO(best_weights)\n    eval_images = find_evaluation_images()\n\n    model.predict(\n        source=eval_images,\n        device=device,\n        save=True,\n        save_txt=True,\n        project=RUNS_DETECT_DIR,\n        name=\"pcb_eval\",\n        exist_ok=True,\n        imgsz=IMG_SIZE,\n        conf=0.25,\n    )\n\n# ------------------------------------------------------------\n# 7. Step 4 ‚Äî Output consolidation\n# ------------------------------------------------------------\n\ndef consolidate_outputs(run_folder):\n    if os.path.exists(FINAL_OUTPUT_DIR):\n        shutil.rmtree(FINAL_OUTPUT_DIR)\n    os.makedirs(FINAL_OUTPUT_DIR, exist_ok=True)\n\n    if os.path.exists(MASK_OUTPUT_DIR):\n        shutil.copytree(MASK_OUTPUT_DIR, os.path.join(FINAL_OUTPUT_DIR, \"masking\"))\n\n    if os.path.exists(run_folder):\n        shutil.copytree(run_folder, os.path.join(FINAL_OUTPUT_DIR, \"training_outputs\"))\n\n    eval_out = os.path.join(RUNS_DETECT_DIR, \"pcb_eval\")\n    if os.path.exists(eval_out):\n        shutil.copytree(eval_out, os.path.join(FINAL_OUTPUT_DIR, \"evaluation_outputs\"))\n\n    with open(os.path.join(FINAL_OUTPUT_DIR, \"report_notes.txt\"), \"w\") as f:\n        f.write(\n            \"AER850 ‚Äì Project 3 Output Structure\\n\"\n            \"masking/              PCB masking steps\\n\"\n            \"training_outputs/     YOLO training results\\n\"\n            \"evaluation_outputs/   Evaluation detections\\n\"\n        )\n\n# ------------------------------------------------------------\n# 8. Main\n# ------------------------------------------------------------\n\nif __name__ == \"__main__\":\n    set_seed(SEED)\n    device = get_device()\n\n    yaml_path = find_data_yaml()\n    motherboard_img = find_motherboard_image()\n\n    if RUN_MASKING:\n        step1_masking(motherboard_img)\n\n    if RUN_TRAINING:\n        run_folder = step2_training(device, yaml_path)\n    else:\n        run_folder = os.path.join(RUNS_DETECT_DIR, MODEL_NAME)\n\n    if RUN_EVALUATION:\n        step3_eval(device, run_folder)\n\n    consolidate_outputs(run_folder)\n\n    print(\"Project 3 completed.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:05:06.338624Z","iopub.execute_input":"2025-12-01T19:05:06.338860Z"}},"outputs":[{"name":"stdout","text":"New https://pypi.org/project/ultralytics/8.3.233 available üòÉ Update with 'pip install -U ultralytics'\nUltralytics 8.3.232 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=False, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/input/aer850-project-3-data-new/Project 3 Data - Kaggle/Project 3 Data/data/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=200, erasing=0.4, exist_ok=True, fliplr=0.3, flipud=0.2, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/input/yolo-weights/yolo-weights/yolo11n.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=pcb_model_best_kaggle, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/detect/pcb_model_best_kaggle, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 24.4MB/s 0.0s\nOverriding model.yaml nc=80 with nc=13\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    433207  ultralytics.nn.modules.head.Detect           [13, [64, 128, 256]]          \nYOLO11n summary: 181 layers, 2,592,375 parameters, 2,592,359 gradients\n\nTransferred 448/499 items from pretrained weights\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.7¬±0.2 ms, read: 27.6¬±19.4 MB/s, size: 361.4 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/aer850-project-3-data-new/Project 3 Data - Kaggle/Project 3 Data/data/train/labels... 544 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 544/544 125.2it/s 4.3s0.0s\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/aer850-project-3-data-new/Project 3 Data - Kaggle/Project 3 Data/data/train is not writable, cache not saved.\nWARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 26, len(boxes) = 108783. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.6¬±0.2 ms, read: 29.5¬±14.0 MB/s, size: 296.6 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/aer850-project-3-data-new/Project 3 Data - Kaggle/Project 3 Data/data/valid/labels... 105 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 105/105 130.7it/s 0.8s1s\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/aer850-project-3-data-new/Project 3 Data - Kaggle/Project 3 Data/data/valid is not writable, cache not saved.\nWARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 26, len(boxes) = 19108. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\nPlotting labels to /kaggle/working/runs/detect/pcb_model_best_kaggle/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000588, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\nImage sizes 1280 train, 1280 val\nUsing 1 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/detect/pcb_model_best_kaggle\u001b[0m\nStarting training for 200 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      1/200       9.8G      2.347      4.584      1.426       1112       1280: 15% ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 20/136 3.4it/s 8.6s<33.7s","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nAER850 ‚Äì Project 3\nKAGGLE FINAL DETECTION SCRIPT (ROBUST + CLEAN LABELS)\n---------------------------------------------------------------\n- Loads Ultralytics from uploaded .whl (no pip install needed)\n- Auto-detects trained best.pt:\n      /kaggle/working/runs/detect/pcb_model_best_kaggle/weights/best.pt\n      or any best.pt under /kaggle/working\n      or any best.pt under /kaggle/input\n- Auto-detects data.yaml and evaluation images\n- Draws small, clean labels for maximum PCB visibility\n- Saves outputs to /kaggle/working/prediction_outputs\n\"\"\"\n\n# ---------------------------------------------------------------\n# 0. LOAD ULTRALYTICS FROM WHEEL\n# ---------------------------------------------------------------\n\nimport os, glob, zipfile, sys, cv2, yaml, torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(\"Searching for Ultralytics wheel...\")\n\nwheel_files = glob.glob(\"/kaggle/input/**/*.whl\", recursive=True)\nif not wheel_files:\n    raise FileNotFoundError(\"Ultralytics .whl file not found in /kaggle/input.\")\n\nWHEEL_PATH = wheel_files[0]\nprint(\"Found wheel:\", WHEEL_PATH)\n\nEXTRACT_DIR = \"/kaggle/working/ultralytics_lib\"\nif os.path.exists(EXTRACT_DIR):\n    import shutil\n    shutil.rmtree(EXTRACT_DIR)\n\nprint(\"Extracting wheel...\")\nwith zipfile.ZipFile(WHEEL_PATH, \"r\") as z:\n    z.extractall(EXTRACT_DIR)\n\nsys.path.insert(0, EXTRACT_DIR)\n\nfrom ultralytics import YOLO\nprint(\"Ultralytics imported successfully.\")\n\n\n# ---------------------------------------------------------------\n# 1. GLOBAL PATHS\n# ---------------------------------------------------------------\n\nINPUT_ROOT = \"/kaggle/input\"\nWORK_ROOT = \"/kaggle/working\"\nSAVE_DIR = os.path.join(WORK_ROOT, \"prediction_outputs\")\n\nos.makedirs(SAVE_DIR, exist_ok=True)\nprint(\"Saving predictions to:\", SAVE_DIR)\n\n\n# ---------------------------------------------------------------\n# 2. FINDERS\n# ---------------------------------------------------------------\n\ndef find_best_pt():\n    \"\"\"Locate best.pt under expected training path, /kaggle/working, or /kaggle/input.\"\"\"\n    print(\"\\nSearching for best.pt...\")\n\n    direct = \"/kaggle/working/runs/detect/pcb_model_best_kaggle/weights/best.pt\"\n    if os.path.exists(direct):\n        print(\"Found best.pt at:\", direct)\n        return direct\n\n    working_list = glob.glob(\"/kaggle/working/**/best.pt\", recursive=True)\n    if working_list:\n        print(\"Found best.pt under /kaggle/working:\", working_list[0])\n        return working_list[0]\n\n    input_list = glob.glob(\"/kaggle/input/**/best.pt\", recursive=True)\n    if input_list:\n        print(\"Found best.pt under /kaggle/input:\", input_list[0])\n        return input_list[0]\n\n    raise FileNotFoundError(\n        \"best.pt not found. Training may not have completed or run folder not attached.\"\n    )\n\n\ndef find_data_yaml():\n    \"\"\"Locate data.yaml anywhere under /kaggle/input.\"\"\"\n    print(\"\\nSearching for data.yaml...\")\n    files = glob.glob(\"/kaggle/input/**/data.yaml\", recursive=True)\n    if not files:\n        raise FileNotFoundError(\"data.yaml not found under /kaggle/input.\")\n    print(\"Using data.yaml:\", files[0])\n    return files[0]\n\n\ndef find_evaluation_images():\n    \"\"\"Locate images inside folders named 'evaluation' under /kaggle/input.\"\"\"\n    print(\"\\nSearching for evaluation images...\")\n    result = []\n    exts = [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.JPG\", \"*.JPEG\", \"*.PNG\"]\n\n    for ext in exts:\n        pattern = os.path.join(\"/kaggle/input\", \"**\", ext)\n        for item in glob.glob(pattern, recursive=True):\n            parent = os.path.basename(os.path.dirname(item)).lower()\n            if parent == \"evaluation\":\n                result.append(item)\n\n    if not result:\n        raise RuntimeError(\"No evaluation images found in a folder named 'evaluation'.\")\n\n    print(\"Found evaluation images:\", len(result))\n    return sorted(result)\n\n\ndef load_class_names(path):\n    \"\"\"Load CLASS_NAMES from data.yaml.\"\"\"\n    with open(path, \"r\") as f:\n        data = yaml.safe_load(f)\n    names = data.get(\"names\")\n    if names is None:\n        raise RuntimeError(\"Missing 'names' in data.yaml.\")\n    print(\"Class names loaded:\", names)\n    return names\n\n\n# ---------------------------------------------------------------\n# 3. SMALL CLEAN LABEL DRAWING\n# ---------------------------------------------------------------\n\nCOLOR_LIST = [\n    (0, 255, 0),\n    (255, 128, 0),\n    (255, 0, 0),\n    (255, 255, 0),\n    (255, 0, 255),\n    (128, 0, 255),\n]\n\ndef draw_clean_boxes(img, results, names):\n    \"\"\"\n    Draw compact bounding boxes and adaptive small labels.\n    Ensures minimal obstruction of PCB features.\n    \"\"\"\n    h, w = img.shape[:2]\n\n    for box in results.boxes:\n        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n        cls = int(box.cls)\n        conf = float(box.conf)\n        text = f\"{names[cls]} {conf:.2f}\"\n\n        color = COLOR_LIST[cls % len(COLOR_LIST)]\n        scale = max(0.3, min(w / 2800, h / 2800))\n        thickness = max(1, int(scale * 2))\n\n        (tw, th), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, scale, thickness)\n\n        cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n        cv2.rectangle(img, (x1, y1 - th - 6), (x1 + tw + 6, y1), color, -1)\n        cv2.putText(\n            img, text, (x1 + 3, y1 - 4),\n            cv2.FONT_HERSHEY_SIMPLEX, scale, (0, 0, 0),\n            max(1, thickness - 1),\n        )\n\n    return img\n\n\n# ---------------------------------------------------------------\n# 4. LOAD MODEL AND FILES\n# ---------------------------------------------------------------\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"\\nUsing device:\", DEVICE)\n\nBEST_PT = find_best_pt()\nDATA_YAML = find_data_yaml()\nEVAL_IMGS = find_evaluation_images()\nCLASS_NAMES = load_class_names(DATA_YAML)\n\nprint(\"\\nLoading trained YOLO model...\")\nmodel = YOLO(BEST_PT)\nprint(\"Model loaded.\")\n\n\n# ---------------------------------------------------------------\n# 5. RUN DETECTION\n# ---------------------------------------------------------------\n\nprint(\"\\nRunning detection...\\n\")\n\ntotal_count = 0\nper_class = {}\n\nfor path in EVAL_IMGS:\n    name = os.path.basename(path)\n    print(\"Processing:\", name)\n\n    img = cv2.imread(path)\n    if img is None:\n        print(\"Could not read image:\", path)\n        continue\n\n    results = model.predict(img, device=DEVICE, conf=0.25, verbose=False)[0]\n\n    for box in results.boxes:\n        cls_name = CLASS_NAMES[int(box.cls)]\n        per_class[cls_name] = per_class.get(cls_name, 0) + 1\n        total_count += 1\n\n    img = draw_clean_boxes(img, results, CLASS_NAMES)\n\n    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.figure(figsize=(10, 8))\n    plt.imshow(rgb)\n    plt.axis(\"off\")\n    plt.title(name)\n    plt.show()\n\n    out_path = os.path.join(SAVE_DIR, \"det_\" + name)\n    cv2.imwrite(out_path, img)\n    print(\"Saved:\", out_path)\n\n\n# ---------------------------------------------------------------\n# 6. SUMMARY\n# ---------------------------------------------------------------\n\nprint(\"\\nDetection Summary\")\nprint(\"------------------\")\nprint(\"Total detections:\", total_count)\nprint()\n\nfor cls, count in per_class.items():\n    print(f\"{cls:20s}: {count}\")\n\nprint(\"\\nAll predictions saved in:\", SAVE_DIR)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}